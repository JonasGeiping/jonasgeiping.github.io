@article{bansal_cold_2022,
 abstract = {Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes. Our code is available at https://github.com/arpitbansal297/Cold-Diffusion-Models},
 archiveprefix = {arXiv},
 author = {Bansal, Arpit and Borgnia, Eitan and Chu, Hong-Min and Li, Jie S. and Kazemi, Hamid and Huang, Furong and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
 copyright = {All rights reserved},
 doi = {10.48550/arXiv.2208.09392},
 eprint = {2208.09392},
 eprinttype = {arxiv},
 journal = {arxiv:2208.09392[cs]},
 keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
 month = {August},
 primaryclass = {cs},
 publisher = {arXiv},
 shorttitle = {Cold Diffusion},
 title = {Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise},
 url = {http://arxiv.org/abs/2208.09392},
 urldate = {2022-10-27},
 year = {2022}
}


@article{somepalli_diffusion_2022,
 abstract = {Cutting-edge diffusion models produce images with high quality and customizability, enabling them to be used for commercial art and graphic design purposes. But do diffusion models create unique works of art, or are they stealing content directly from their training sets? In this work, we study image retrieval frameworks that enable us to compare generated images with training samples and detect when content has been replicated. Applying our frameworks to diffusion models trained on multiple datasets including Oxford flowers, Celeb-A, ImageNet, and LAION, we discuss how factors such as training set size impact rates of content replication. We also identify cases where diffusion models, including the popular Stable Diffusion model, blatantly copy from their training data.},
 archiveprefix = {arXiv},
 author = {Somepalli, Gowthami and Singla, Vasu and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
 doi = {10.48550/arXiv.2212.03860},
 eprint = {2212.03860},
 eprinttype = {arxiv},
 journal = {arxiv:2212.03860[cs]},
 keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning},
 month = {December},
 primaryclass = {cs},
 publisher = {arXiv},
 shorttitle = {Diffusion Art or Digital Forgery?},
 title = {Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models},
 url = {http://arxiv.org/abs/2212.03860},
 urldate = {2022-12-08},
 year = {2022}
}

